from training import get_features_dim_target, get_data
import tensorflow as tf
from absl import app, flags
import math
from kongming.layers import VocabLookup
FLAGS = flags.FLAGS
'''
This file is to testify the calibrated model is doing the right thing: applying a lookup layer to the score.
The inputs should satisfy:
1. test_calibrated_model should be generated based on test_model
2. the look-up table was *GENERATED during CALIBRATION*, not from the asset of calibrated model.
3. a dataset that models can predict on.
It will raise an error if the calibrated model output is not equal to score + lookup.
'''


flags.DEFINE_integer('score_grid_count', default=10000, help='Grid count of scores')
flags.DEFINE_string('test_model', default="output/model/basic_0.3", help='The conversion model to test')
flags.DEFINE_string('test_calibrated_model', default="output/model_calibrated/grid_count=10000", help='The calibrated conversion model to test')
flags.DEFINE_string('test_lookup_table', default="conversion-python/assets_string/ag_score_mod.txt", help='The lookup table generated by calibration training.')
flags.DEFINE_integer('batches_to_check', default=50, help='Number of batches to check in the data')

def calibration_check(argv):
    # load some data, it doesn't matter if the data is related to the models, as long as models can predict on the data
    model_features, model_dim_feature, model_targets = get_features_dim_target()
    data, _ = get_data(model_features, [model_dim_feature], model_targets, FLAGS.sample_weight_col)

    # load a model and an associated calibrated model
    model = tf.keras.models.load_model(FLAGS.test_model, compile=True)
    calibrated_model = tf.keras.models.load_model(FLAGS.test_calibrated_model, compile=True)

    # load the look at table *GENERATED during CALIBRATION*, not from the asset of calibrated model
    lookup_out = VocabLookup(vocab_path=FLAGS.test_lookup_table, key_dtype=tf.string, value_dtype=tf.float64)
    fstring = "{" + ":.{}f".format(int(math.log10(FLAGS.score_grid_count))) + "}"

    # take first batch of data
    for x in data.take(FLAGS.batches_to_check):
        score = model.predict(x[0])
        calibrated_score = calibrated_model.predict(x[0])
        for i in range(len(score)):
            adgroupid = x[0]['AdGroupId'][i].numpy()
            score_single = min(1-1/FLAGS.score_grid_count, score[i][0])
            lookup_score = lookup_out(tf.constant(fstring.format(adgroupid + score_single), dtype=tf.string))
            if lookup_score.numpy() != calibrated_score[i][0]:
                raise Exception("calibrated model output is not aligned with score+lookuplayer output!")


if __name__ == '__main__':
    app.run(calibration_check)


